"""
Egyszer≈±s√≠tett vizualiz√°ci√≥k a RAG vs Full Context benchmark eredm√©nyeihez
Csak 7 √°bra: 6 alapvet≈ë + 1 t√©mak√∂r√∂nk√©nti
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Magyar nyelv t√°mogat√°s
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

def load_latest_results():
    """Leg√∫jabb benchmark eredm√©nyek bet√∂lt√©se docs mapp√°b√≥l"""
    # Keres√©s eredm√©nyekre docs mapp√°ban √©s gy√∂k√©rben is
    result_files = []
    
    # El≈ësz√∂r docs mapp√°ban
    docs_path = Path('docs')
    if docs_path.exists():
        result_files.extend(docs_path.glob('benchmark_results_*.csv'))
        result_files.extend(docs_path.glob('temp_optimized_results_50.csv'))
        result_files.extend(docs_path.glob('optimized_results_*.csv'))
        result_files.extend(docs_path.glob('temp_optimized_results_*.csv'))
        result_files.extend(docs_path.glob('temp_results_*.csv'))
    
    # Ha nincs a docs-ban, gy√∂k√©rben keres√©s
    if not result_files:
        result_files.extend(Path('.').glob('benchmark_results_*.csv'))
        result_files.extend(Path('.').glob('temp_optimized_results_50.csv'))
        result_files.extend(Path('.').glob('optimized_results_*.csv'))
        result_files.extend(Path('.').glob('*results*.csv'))
    
    if not result_files:
        raise FileNotFoundError("Nincs tal√°lat eredm√©ny f√°jl!")
    
    # Leg√∫jabb f√°jl
    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
    print(f"Benchmark eredm√©nyek bet√∂lt√©se: {latest_file}")
    
    return pd.read_csv(latest_file, encoding='utf-8')

def analyze_data(df):
    """Alapvet≈ë adatelemz√©s"""
    print("="*60)
    print("ADATELEMZ√âS √ñSSZEFOGLAL√ì")
    print("="*60)
    
    print(f"√ñsszes rekord: {len(df)}")
    print(f"K√©rd√©sek sz√°ma: {df['question_id'].nunique()}")
    print(f"M√≥dszerek: {df['method'].unique()}")
    print(f"AI modellek: {df['ai_model'].unique()}")
    
    # Hib√°k
    errors = df[df['error'].notna()]
    successful = df[df['error'].isna()]
    
    print(f"\\nSikeres tesztek: {len(successful)} ({len(successful)/len(df)*100:.1f}%)")
    print(f"Hib√°s tesztek: {len(errors)} ({len(errors)/len(df)*100:.1f}%)")
    
    if len(errors) > 0:
        print("\\nHib√°k megoszl√°sa:")
        error_breakdown = errors.groupby(['method', 'ai_model']).size()
        print(error_breakdown)
    
    return successful, errors

def create_simplified_charts(successful_df, filename):
    """Egyszer≈±s√≠tett grafikonok - csak 7 √°bra"""
    
    if len(successful_df) == 0:
        print("Nincs sikeres adat a vizualiz√°ci√≥hoz!")
        return
    
    # Set up the plotting style
    plt.style.use('default')
    sns.set_palette("husl")
    
    # ELS≈ê √ÅBRA: 6 alapvet≈ë grafikon
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1.1 V√°lasz min≈ës√©g (Word Overlap)
    ax1 = axes[0, 0]
    quality_data = successful_df.groupby(['method', 'ai_model'])['word_overlap'].mean().unstack()
    quality_data.plot(kind='bar', ax=ax1, color=['#2E8B57', '#FF6B6B'])
    ax1.set_title('√Åtlagos V√°lasz Min≈ës√©g (Word Overlap)', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Word Overlap Score')
    ax1.set_xlabel('M√≥dszer')
    ax1.legend(title='AI Modell')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(axis='y', alpha=0.3)
    
    # 1.2 V√°laszid≈ë √∂sszehasonl√≠t√°s
    ax2 = axes[0, 1]
    time_data = successful_df.groupby(['method', 'ai_model'])['generation_time'].mean().unstack()
    time_data.plot(kind='bar', ax=ax2, color=['#4CAF50', '#FF9800'])
    ax2.set_title('√Åtlagos V√°laszid≈ë (m√°sodperc)', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Id≈ë (s)')
    ax2.set_xlabel('M√≥dszer')
    ax2.legend(title='AI Modell')
    ax2.tick_params(axis='x', rotation=45)
    ax2.grid(axis='y', alpha=0.3)
    
    # 1.3 K√∂lts√©g √∂sszehasonl√≠t√°s
    ax3 = axes[0, 2]
    cost_data = successful_df.groupby(['method', 'ai_model'])['cost_estimate'].sum().unstack()
    cost_data.plot(kind='bar', ax=ax3, color=['#9C27B0', '#FF5722'])
    ax3.set_title('√ñsszes Becs√ºlt K√∂lts√©g ($)', fontsize=12, fontweight='bold')
    ax3.set_ylabel('K√∂lts√©g ($)')
    ax3.set_xlabel('M√≥dszer')
    ax3.legend(title='AI Modell')
    ax3.tick_params(axis='x', rotation=45)
    ax3.grid(axis='y', alpha=0.3)
    
    # 1.4 Kontextus m√©ret hat√°sa
    ax4 = axes[1, 0]
    context_effect = successful_df.groupby('method')[['context_size', 'word_overlap']].mean()
    
    ax4_twin = ax4.twinx()
    bars = ax4.bar(context_effect.index, context_effect['context_size'], alpha=0.7, color='lightblue', label='Kontextus m√©ret')
    line = ax4_twin.plot(context_effect.index, context_effect['word_overlap'], color='red', marker='o', linewidth=3, markersize=8, label='Min≈ës√©g')
    
    ax4.set_title('Kontextus M√©ret vs Min≈ës√©g', fontsize=12, fontweight='bold')
    ax4.set_ylabel('Kontextus m√©ret (karakterek)', color='blue')
    ax4_twin.set_ylabel('Word Overlap Score', color='red')
    
    # 1.5 Token haszn√°lat
    ax5 = axes[1, 1]
    successful_df['config'] = successful_df['method'] + ' + ' + successful_df['ai_model']
    sns.boxplot(data=successful_df, x='config', y='tokens_used', ax=ax5)
    ax5.set_title('Token Haszn√°lat Eloszl√°sa', fontsize=12, fontweight='bold')
    ax5.set_xlabel('Konfigur√°ci√≥')
    ax5.set_ylabel('Token sz√°m')
    ax5.tick_params(axis='x', rotation=45)
    
    # 1.6 Kombin√°lt pontsz√°m
    ax6 = axes[1, 2]
    summary_stats = successful_df.groupby(['method', 'ai_model']).agg({
        'word_overlap': 'mean',
        'generation_time': 'mean',
        'cost_estimate': 'sum'
    })
    
    # Normaliz√°l√°s √©s s√∫lyoz√°s
    summary_stats['speed_norm'] = 1 - (summary_stats['generation_time'] / summary_stats['generation_time'].max())
    summary_stats['cost_norm'] = 1 - (summary_stats['cost_estimate'] / summary_stats['cost_estimate'].max())
    
    summary_stats['combined_score'] = (
        summary_stats['word_overlap'] * 0.6 +  # Min≈ës√©g 60%
        summary_stats['speed_norm'] * 0.2 +     # Sebess√©g 20%
        summary_stats['cost_norm'] * 0.2        # K√∂lts√©ghat√©konys√°g 20%
    )
    
    final_scores = summary_stats['combined_score'].unstack()
    final_scores.plot(kind='bar', ax=ax6, color=['#00BCD4', '#FFC107'])
    ax6.set_title('V√©gs≈ë Kombin√°lt Pontsz√°m\\n(Min≈ës√©g 60% + Sebess√©g 20% + K√∂lts√©g 20%)', 
                  fontsize=12, fontweight='bold')
    ax6.set_ylabel('Kombin√°lt Pontsz√°m')
    ax6.set_xlabel('M√≥dszer')
    ax6.legend(title='AI Modell')
    ax6.tick_params(axis='x', rotation=45)
    ax6.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    
    # PNG f√°jlok ment√©se docs mapp√°ba
    docs_path = 'docs'
    if not os.path.exists(docs_path):
        os.makedirs(docs_path)
    
    main_chart_filename = f'docs/main_comparison_{filename[:-4]}.png'
    plt.savefig(main_chart_filename, dpi=300, bbox_inches='tight')
    print(f"F≈ë √∂sszehasonl√≠t√≥ grafikon mentve: {main_chart_filename}")
    plt.show()
    
    # M√ÅSODIK √ÅBRA: T√©mak√∂r√∂nk√©nti teljes√≠tm√©ny
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    # T√©mak√∂r√∂nk√©nti √°tlagok
    topic_performance = successful_df.groupby(['topic', 'method'])['word_overlap'].mean().unstack()
    
    # Heatmap
    sns.heatmap(topic_performance, annot=True, fmt='.2f', cmap='RdYlGn', 
                center=0.5, ax=ax, cbar_kws={'label': 'Word Overlap Score'})
    ax.set_title('T√©mak√∂r√∂nk√©nti Teljes√≠tm√©ny', fontsize=14, fontweight='bold')
    ax.set_xlabel('M√≥dszer')
    ax.set_ylabel('T√©mak√∂r')
    
    plt.tight_layout()
    
    # PNG f√°jl ment√©se docs mapp√°ba
    docs_path = 'docs'
    if not os.path.exists(docs_path):
        os.makedirs(docs_path)
    
    topic_chart_filename = f'docs/topic_performance_{filename[:-4]}.png'
    plt.savefig(topic_chart_filename, dpi=300, bbox_inches='tight')
    print(f"T√©mak√∂r√∂nk√©nti teljes√≠tm√©ny grafikon mentve: {topic_chart_filename}")
    plt.show()
    
    return summary_stats

def print_summary_stats(successful_df, summary_stats):
    """√ñsszefoglal√≥ statisztik√°k ki√≠r√°sa"""
    print("\\n" + "="*60)
    print("R√âSZLETES STATISZTIKAI √ñSSZEFOGLAL√ì")
    print("="*60)
    
    # Alapvet≈ë metrik√°k
    for method in ['RAG', 'FullContext']:
        for model in ['Gemini', 'OpenAI']:
            subset = successful_df[(successful_df['method'] == method) & 
                                 (successful_df['ai_model'] == model)]
            if len(subset) > 0:
                avg_quality = subset['word_overlap'].mean()
                avg_time = subset['generation_time'].mean()
                total_cost = subset['cost_estimate'].sum()
                
                print(f"\\n{method} + {model}:")
                print(f"  √Åtlagos min≈ës√©g: {avg_quality:.3f}")
                print(f"  √Åtlagos id≈ë: {avg_time:.2f}s")
                print(f"  √ñsszes k√∂lts√©g: ${total_cost:.5f}")
    
    # Kombin√°lt pontsz√°mok
    print(f"\\nüìä V√âGS≈ê KOMBIN√ÅLT PONTSZ√ÅMOK:")
    for idx, score in summary_stats['combined_score'].items():
        method, model = idx
        print(f"  {method} + {model}: {score:.3f}")

def main():
    """F≈ë program - egyszer≈±s√≠tett vizualiz√°ci√≥"""
    try:
        # Adatok bet√∂lt√©se
        df = load_latest_results()
        
        # Alapvet≈ë elemz√©s
        successful_df, errors = analyze_data(df)
        
        if len(successful_df) == 0:
            print("‚ùå Nincs sikeres adat a vizualiz√°ci√≥hoz!")
            return
        
        # Egyszer≈±s√≠tett grafikonok (7 √°bra)
        summary_stats = create_simplified_charts(successful_df, 'optimized_results.csv')
        
        # Statisztikai √∂sszefoglal√≥
        print_summary_stats(successful_df, summary_stats)
        
        print("\nüéâ Egyszer≈±s√≠tett vizualiz√°ci√≥ k√©sz!")
        print("üìä K√©sz√ºlt 2 √°bra a docs/ mapp√°ban:")
        print("   1. docs/main_comparison_optimized_results.png (6 alapvet≈ë grafikon)")
        print("   2. docs/topic_performance_optimized_results.png (t√©mak√∂r√∂nk√©nti teljes√≠tm√©ny)")
        print("\nüìÅ Minden output (CSV + PNG) mostant√≥l a docs/ mapp√°ban ment≈ëdik.")
        print("üîÑ A k√∂vetkez≈ë futtat√°sn√°l a program automatikusan ott keresi ≈ëket.")
        
    except Exception as e:
        print(f"‚ùå Hiba a vizualiz√°ci√≥ sor√°n: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()